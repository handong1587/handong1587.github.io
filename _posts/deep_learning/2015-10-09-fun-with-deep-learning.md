---
layout: post
category: deep_learning
title: Fun With Deep Learning
date: 2015-10-09
---

# Painting

**Artist Agent: A Reinforcement Learning Approach to Automatic Stroke Generation in Oriental Ink Painting**

- intro: ICML 2012
- arxiv: [https://arxiv.org/abs/1206.4634](https://arxiv.org/abs/1206.4634)

## Neural Art

**A Neural Algorithm of Artistic Style**

![](/assets/fun_with_dl/a_nerual_algorithm_of_artistic_style.jpg)

- arxiv: [http://arxiv.org/abs/1508.06576](http://arxiv.org/abs/1508.06576)
- gitxiv: [http://gitxiv.com/posts/jG46ukGod8R7Rdtud/a-neural-algorithm-of-artistic-style](http://gitxiv.com/posts/jG46ukGod8R7Rdtud/a-neural-algorithm-of-artistic-style)
- github: [https://github.com/kaishengtai/neuralart](https://github.com/kaishengtai/neuralart)
- github: [https://github.com/jcjohnson/neural-style](https://github.com/jcjohnson/neural-style)
- github: [https://github.com/andersbll/neural_artistic_style](https://github.com/andersbll/neural_artistic_style)
- ipn: [http://nbviewer.ipython.org/github/Lasagne/Recipes/blob/master/examples/styletransfer/Art%20Style%20Transfer.ipynb](http://nbviewer.ipython.org/github/Lasagne/Recipes/blob/master/examples/styletransfer/Art%20Style%20Transfer.ipynb)
- github: [https://github.com/mbartoli/neural-animation](https://github.com/mbartoli/neural-animation)
- github: [https://github.com/memisevic/artify](https://github.com/memisevic/artify)
- github: [https://github.com/mattya/chainer-gogh](https://github.com/mattya/chainer-gogh)
- github(TensorFlow): [https://github.com/anishathalye/neural-style](https://github.com/anishathalye/neural-style)
- github: [https://github.com/woodrush/neural-art-tf](https://github.com/woodrush/neural-art-tf)
- github: [https://github.com/dmlc/mxnet/tree/master/example/neural-style](https://github.com/dmlc/mxnet/tree/master/example/neural-style)
- demo: [http://deepart.io/](http://deepart.io/)
- github: [https://github.com/Teaonly/easyStyle](https://github.com/Teaonly/easyStyle)
- github: [https://github.com/ckmarkoh/neuralart_tensorflow](https://github.com/ckmarkoh/neuralart_tensorflow)
- github: [https://github.com/fzliu/style-transfer](https://github.com/fzliu/style-transfer)
- github: [https://github.com/titu1994/Neural-Style-Transfer](https://github.com/titu1994/Neural-Style-Transfer)
- github: [https://github.com/saikatbsk/Vincent-AI-Artist](https://github.com/saikatbsk/Vincent-AI-Artist)
- github: [https://github.com/zhaw/neural_style](https://github.com/zhaw/neural_style)

**Image Style Transfer Using Convolutional Neural Networks**

- paper: [www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf](www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf)

**Artificial Startup Style: Neural art about startup fashion**

![](https://cdn-images-1.medium.com/max/800/1*n2cmWDB42iUij8TCil9yLA.png)

- blog: [https://medium.com/data-engineering/artificial-startup-style-437f6090b1f7#.8u06gq42e](https://medium.com/data-engineering/artificial-startup-style-437f6090b1f7#.8u06gq42e)

**From Pixels to Paragraphs: How artistic experiments with deep learning guard us from hype**

- blog: [https://medium.com/@genekogan/from-pixels-to-paragraphs-eb2763da0e9b#.er3djn9z9](https://medium.com/@genekogan/from-pixels-to-paragraphs-eb2763da0e9b#.er3djn9z9)

**Experiments with style transfer**

- website: [http://mtyka.github.io/code/2015/10/02/experiments-with-style-transfer.html](http://mtyka.github.io/code/2015/10/02/experiments-with-style-transfer.html)

**Style Transfer for Headshot Portraits (SIGGRAPH 2014)**

![](https://people.csail.mit.edu/yichangshih/portrait_web/teaser.jpg)

- project: [https://people.csail.mit.edu/yichangshih/portrait_web/](https://people.csail.mit.edu/yichangshih/portrait_web/)

**Teaching recurrent Neural Networks about Monet**

![](/assets/fun_with_dl/keras_monet_output_sample.png)

- blog: [http://blog.manugarri.com/teaching-recurrent-neural-networks-about-monet/](http://blog.manugarri.com/teaching-recurrent-neural-networks-about-monet/)
- github: [https://github.com/manugarri/keras_monet](https://github.com/manugarri/keras_monet)

**Content Aware Neural Style Transfer**

- arxiv: [http://arxiv.org/abs/1601.04568](http://arxiv.org/abs/1601.04568)

**Combining Markov Random Fields and Convolutional Neural Networks for Image Synthesis**

<img src="https://raw.githubusercontent.com/chuanli11/CNNMRF/master/data/examples/content.jpg" width="150" />
<img src="https://raw.githubusercontent.com/chuanli11/CNNMRF/master/data/examples/style.jpg" width="150" />
<img src="https://raw.githubusercontent.com/chuanli11/CNNMRF/master/data/examples/Interpolation/3_balanced.png" width="150" />

- arxiv: [http://arxiv.org/abs/1601.04589](http://arxiv.org/abs/1601.04589)
- github: [https://github.com/chuanli11/CNNMRF](https://github.com/chuanli11/CNNMRF)

**Stylenet: Neural Network with Style Synthesis**

- github: [https://github.com/machrisaa/stylenet](https://github.com/machrisaa/stylenet)

**Ostagram**

- intro: This program presents web-service for algorithm combining the content of one image 
with the style of another image using convolutional neural networks
- github: [https://github.com/SergeyMorugin/ostagram](https://github.com/SergeyMorugin/ostagram)

**Exploring the Neural Algorithm of Artistic Style**

- intro: A short class project report
- arxiv: [http://arxiv.org/abs/1602.07188](http://arxiv.org/abs/1602.07188)

**Perceptual Losses for Real-Time Style Transfer and Super-Resolution**

![](https://github.com/jcjohnson/fast-neural-style/blob/master/images/webcam.gif?raw=true)

- intro: Justin Johnson, Alexandre Alahi, Li Fei-Fei. ECCV 2016
- arxiv: [http://arxiv.org/abs/1603.08155](http://arxiv.org/abs/1603.08155)
- github: [https://github.com/jcjohnson/fast-neural-style](https://github.com/jcjohnson/fast-neural-style)
- github: [https://github.com/yusuketomoto/chainer-fast-neuralstyle](https://github.com/yusuketomoto/chainer-fast-neuralstyle)
- github: [https://github.com/awentzonline/keras-rtst](https://github.com/awentzonline/keras-rtst)
- github(Keras): [https://github.com/titu1994/Fast-Neural-Style](https://github.com/titu1994/Fast-Neural-Style)
- gtihub(Tensorflow): [https://github.com/junrushao1994/fast-neural-style.tf] (https://github.com/junrushao1994/fast-neural-style.tf)
- github(PyTorch): [https://github.com/bengxy/FastNeuralStyle](https://github.com/bengxy/FastNeuralStyle)

**Image transformation networks with fancy loss functions**

- intro: Fast neural style in tensorflow based on [http://arxiv.org/abs/1603.08155](http://arxiv.org/abs/1603.08155)
- blog: [http://olavnymoen.com/2016/07/07/image-transformation-network](http://olavnymoen.com/2016/07/07/image-transformation-network)
- github: [https://github.com/OlavHN/fast-neural-style](https://github.com/OlavHN/fast-neural-style)

**Improving the Neural Algorithm of Artistic Style**

- arxiv: [http://arxiv.org/abs/1605.04603](http://arxiv.org/abs/1605.04603)

**CubistMirror: an openframeworks app which repeatedly applies real-time style transfer on a webcam**

![](https://raw.githubusercontent.com/genekogan/CubistMirror/master/photos/cubist_mirror_1.jpg)

- github: [https://github.com/genekogan/CubistMirror](https://github.com/genekogan/CubistMirror)

**Transfer Style But Not Color**

![](https://raw.githubusercontent.com/pavelgonchar/color-independent-style-transfer/master/results-ny.jpg)

- blog: [http://blog.deepart.io/2016/06/04/color-independent-style-transfer/](http://blog.deepart.io/2016/06/04/color-independent-style-transfer/)
- github: [https://github.com/pavelgonchar/color-independent-style-transfer](https://github.com/pavelgonchar/color-independent-style-transfer)

**neural-art-mini: Lightweight version of mxnet neural art implementation**

- intro: Lightweight version of mxnet neural art implementation using ~4.8M SqueezeNet model. 
Compressed model is less than 500KB
- github: [https://github.com/pavelgonchar/neural-art-mini](https://github.com/pavelgonchar/neural-art-mini)

**Preserving Color in Neural Artistic Style Transfer**

- arxiv: [http://arxiv.org/abs/1606.05897](http://arxiv.org/abs/1606.05897)

**End to End Neural Art with Generative Models**

![](https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/art/net.png)

- blog: [http://dmlc.ml/mxnet/2016/06/20/end-to-end-neural-style.html](http://dmlc.ml/mxnet/2016/06/20/end-to-end-neural-style.html)
- github: [https://github.com/dmlc/mxnet/tree/master/example/neural-style](https://github.com/dmlc/mxnet/tree/master/example/neural-style)

**Neural Style Explained**

- blog: [http://kvfrans.com/neural-style-explained/](http://kvfrans.com/neural-style-explained/)
- github: [https://github.com/kvfrans/neural-style](https://github.com/kvfrans/neural-style)

**Texture Networks: Feed-forward Synthesis of Textures and Stylized Images**

- intro: IMCL 2016
- arxiv: [http://arxiv.org/abs/1603.03417](http://arxiv.org/abs/1603.03417)
- github: [https://github.com/DmitryUlyanov/texture_nets](https://github.com/DmitryUlyanov/texture_nets)
- notes: [https://blog.acolyer.org/2016/09/23/texture-networks-feed-forward-synthesis-of-textures-and-stylized-images/](https://blog.acolyer.org/2016/09/23/texture-networks-feed-forward-synthesis-of-textures-and-stylized-images/)
- github: [https://github.com/tgyg-jegli/tf_texture_net](https://github.com/tgyg-jegli/tf_texture_net)

**Learning Typographic Style**

- arxiv: [https://arxiv.org/abs/1603.04000](https://arxiv.org/abs/1603.04000)

**Instance Normalization: The Missing Ingredient for Fast Stylization**

- arxiv: [http://arxiv.org/abs/1607.08022](http://arxiv.org/abs/1607.08022)

**Painting style transfer for head portraits using convolutional neural networks**

- paper: [http://dl.acm.org/citation.cfm?id=2925968](http://dl.acm.org/citation.cfm?id=2925968)
- sci-hub: [http://dl.acm.org.sci-hub.cc/citation.cfm?doid=2897824.2925968](http://dl.acm.org.sci-hub.cc/citation.cfm?doid=2897824.2925968)

**Style-Transfer via Texture-Synthesis**

- arxiv: [http://arxiv.org/abs/1609.03057](http://arxiv.org/abs/1609.03057)

**neural-style-tf: TensorFlow implementation of Neural Style**

- github: [https://github.com/cysmith/neural-style-tf](https://github.com/cysmith/neural-style-tf)

**Deep Convolutional Networks as Models of Generalization and Blending Within Visual Creativity**

- intro: In Proceedings of the 7th International Conference on Computational Creativity. Palo Alto: Association for the Advancement of Artificial Intelligence (AAAI) Press (2016)
- arxiv: [https://arxiv.org/abs/1610.02478](https://arxiv.org/abs/1610.02478)

**A Learned Representation For Artistic Style**

- intro: Google Brain
- arxiv: [https://arxiv.org/abs/1610.07629](https://arxiv.org/abs/1610.07629)
- blog: [https://research.googleblog.com/2016/10/supercharging-style-transfer.html](https://research.googleblog.com/2016/10/supercharging-style-transfer.html)
- github: [https://github.com/tensorflow/magenta/tree/master/magenta/models/image_stylization](https://github.com/tensorflow/magenta/tree/master/magenta/models/image_stylization)
- github(Tensorflow): [https://github.com/Heumi/Fast_Multi_Style_Transfer-tf](https://github.com/Heumi/Fast_Multi_Style_Transfer-tf)

**How to Fake It As an Artist with Docker, AWS and Deep Learning**

- blog: [https://medium.com/@lherrera/how-to-fake-it-as-an-artist-with-docker-aws-and-deep-learning-6d42f4acd890#.eq9gcgkzh](https://medium.com/@lherrera/how-to-fake-it-as-an-artist-with-docker-aws-and-deep-learning-6d42f4acd890#.eq9gcgkzh)

**Multistyle Pastiche Generator**

- blog: [https://magenta.tensorflow.org/2016/11/01/multistyle-pastiche-generator/](https://magenta.tensorflow.org/2016/11/01/multistyle-pastiche-generator/)

**Fast Style Transfer in TensorFlow**

- intro: Video Stylization, Image Stylization
- github: [https://github.com/lengstrom/fast-style-transfer](https://github.com/lengstrom/fast-style-transfer)

**Neural Style Transfer For Chinese Fonts**

![](https://raw.githubusercontent.com/kaonashi-tyc/Rewrite/master/images/mixed_font.gif)

- github: [https://github.com/kaonashi-tyc/Rewrite](https://github.com/kaonashi-tyc/Rewrite)

**Neural Style Representations and the Large-Scale Classification of Artistic Style**

- arxiv: [https://arxiv.org/abs/1611.05368](https://arxiv.org/abs/1611.05368)

**Controlling Perceptual Factors in Neural Style Transfer**

- intro: University of Tubingen & Adobe Research
- arxiv: [https://arxiv.org/abs/1611.07865](https://arxiv.org/abs/1611.07865)

**Awesome Typography: Statistics-Based Text Effects Transfer**

- arxiv: [https://arxiv.org/abs/1611.09026](https://arxiv.org/abs/1611.09026)

**Fast Patch-based Style Transfer of Arbitrary Style**

- arxiv: [https://arxiv.org/abs/1612.04337](https://arxiv.org/abs/1612.04337)
- github: [https://github.com/rtqichen/style-swap](https://github.com/rtqichen/style-swap)

**Demystifying Neural Style Transfer**

- intro: IJCAI 2017
- arxiv: [https://arxiv.org/abs/1701.01036](https://arxiv.org/abs/1701.01036)
- github: [https://github.com/lyttonhao/Neural-Style-MMD](https://github.com/lyttonhao/Neural-Style-MMD)

**Son of Zorn's Lemma: Targeted Style Transfer Using Instance-aware Semantic Segmentation**

- arxiv: [https://arxiv.org/abs/1701.02357](https://arxiv.org/abs/1701.02357)

**Bringing Impressionism to Life with Neural Style Transfer in Come Swim**

- intro: a case study of how Neural Style Transfer can be used in a movie production context
- keywords: Kristen Stewart !
- arxiv: [https://arxiv.org/abs/1701.04928](https://arxiv.org/abs/1701.04928)

**Pytorch tutorials for Neural Style transfert**

- github: [https://github.com/alexis-jacq/Pytorch-Tutorials](https://github.com/alexis-jacq/Pytorch-Tutorials)

**Stable and Controllable Neural Texture Synthesis and Style Transfer Using Histogram Losses**

- arxiv: [https://arxiv.org/abs/1701.08893](https://arxiv.org/abs/1701.08893)

**Arbitrary Style Transfer In Real-Time With Adaptive Instance Normalization**

- intro: ICCV 2017. Cornell University
- paper: [https://openreview.net/pdf?id=B1fUVMzKg](https://openreview.net/pdf?id=B1fUVMzKg)
- github(Torch): [https://github.com/xunhuang1995/AdaIN-style](https://github.com/xunhuang1995/AdaIN-style)
- github(TensorFlow): [https://github.com/elleryqueenhomels/arbitrary_style_transfer](https://github.com/elleryqueenhomels/arbitrary_style_transfer)

**Picking an optimizer for Style Transfer**

- blog: [https://medium.com/slavv/picking-an-optimizer-for-style-transfer-86e7b8cba84b#.cgv2oreaq](https://medium.com/slavv/picking-an-optimizer-for-style-transfer-86e7b8cba84b#.cgv2oreaq)
- github: [https://github.com/slavivanov/Style-Tranfer](https://github.com/slavivanov/Style-Tranfer)

**Multi-style Generative Network for Real-time Transfer**

[https://arxiv.org/abs/1703.06953](https://arxiv.org/abs/1703.06953)

**Deep Photo Style Transfer**

- arxiv: [https://arxiv.org/abs/1703.07511](https://arxiv.org/abs/1703.07511)
- github(Torch): [https://github.com/luanfujun/deep-photo-styletransfer](https://github.com/luanfujun/deep-photo-styletransfer)
- github(Docker): [https://github.com/martinbenson/deep-photo-styletransfer](https://github.com/martinbenson/deep-photo-styletransfer)

**Lightweight Neural Style on Pytorch**

[https://github.com/lizeng614/SqueezeNet-Neural-Style-Pytorch](https://github.com/lizeng614/SqueezeNet-Neural-Style-Pytorch)

**StyleBank: An Explicit Representation for Neural Image Style Transfer**

- intro: CVPR 2017
- arxiv: [https://arxiv.org/abs/1703.09210](https://arxiv.org/abs/1703.09210)

**How to Make an Image More Memorable? A Deep Style Transfer Approach**

- intro: ACM ICMR 2017
- arxiv: [https://arxiv.org/abs/1704.01745](https://arxiv.org/abs/1704.01745)

**Visual Attribute Transfer through Deep Image Analogy**

- intro: SIGGRAPH 2017
- keywords: Deep Image Analogy
- arxiv: [https://arxiv.org/abs/1705.01088](https://arxiv.org/abs/1705.01088)
- github: [https://github.com/msracver/Deep-Image-Analogy](https://github.com/msracver/Deep-Image-Analogy)

**Characterizing and Improving Stability in Neural Style Transfer**

[https://arxiv.org/abs/1705.02092](https://arxiv.org/abs/1705.02092)

**Towards Metamerism via Foveated Style Transfer**

[https://arxiv.org/abs/1705.10041](https://arxiv.org/abs/1705.10041)

**Style Transfer for Sketches with Enhanced Residual U-net and Auxiliary Classifier GAN**

[https://arxiv.org/abs/1706.03319](https://arxiv.org/abs/1706.03319)

**Meta Networks for Neural Style Transfer**

- arxiv: [https://arxiv.org/abs/1709.04111](https://arxiv.org/abs/1709.04111)
- github: [https://github.com/FalongShen/styletransfer](https://github.com/FalongShen/styletransfer)

**Neural Color Transfer between Images**

- intro: Hong Kong University of Science and Technology & Microsoft Research
- arxiv: [https://arxiv.org/abs/1710.00756](https://arxiv.org/abs/1710.00756)

**Improved Style Transfer by Respecting Inter-layer Correlations**

[https://arxiv.org/abs/1801.01933](https://arxiv.org/abs/1801.01933)

**Face Destylization**

[https://arxiv.org/abs/1802.01237](https://arxiv.org/abs/1802.01237)

**Unsupervised Typography Transfer**

[https://arxiv.org/abs/1802.02595](https://arxiv.org/abs/1802.02595)

**Stereoscopic Neural Style Transfer**

- intro: CVPR 2018
- arxiv: [https://arxiv.org/abs/1802.10591](https://arxiv.org/abs/1802.10591)

**Arbitrary Style Transfer with Deep Feature Reshuffle**

[https://arxiv.org/abs/1805.04103](https://arxiv.org/abs/1805.04103)

**Avatar-Net: Multi-scale Zero-shot Style Transfer by Feature Decoration**

- intro: CVPR 2018. CUHK & SenseTime
- arxiv: [https://arxiv.org/abs/1805.03857](https://arxiv.org/abs/1805.03857)

**Beyond Textures: Learning from Multi-domain Artistic Images for Arbitrary Style Transfer**

[https://arxiv.org/abs/1805.09987](https://arxiv.org/abs/1805.09987)

**A Comprehensive Comparison between Neural Style Transfer and Universal Style Transfer**

[https://arxiv.org/abs/1806.00868](https://arxiv.org/abs/1806.00868)

**Unbiased Image Style Transfer**

[https://arxiv.org/abs/1807.01424](https://arxiv.org/abs/1807.01424)

**Uncorrelated Feature Encoding for Faster Image Style Transfer**

[https://arxiv.org/abs/1807.01493](https://arxiv.org/abs/1807.01493)

**Adjustable Real-time Style Transfer**

- intro: University of Illinois at Urbana-Champaign && Google Brain
- arxiv: [https://arxiv.org/abs/1811.08560](https://arxiv.org/abs/1811.08560)

## Neural Art On Audio

**MSc AI Project on generative deep networks and neural style transfer for audio**

- github: [https://github.com/Fr-d-rik/generative_audio](https://github.com/Fr-d-rik/generative_audio)
- project report: [https://github.com/Fr-d-rik/generative_audio/blob/master/docs/project_report.pdf](https://github.com/Fr-d-rik/generative_audio/blob/master/docs/project_report.pdf)

**Neural Song Style**

- intro: Audio style transfer AI
- github: [https://github.com/rupeshs/neuralsongstyle](https://github.com/rupeshs/neuralsongstyle)

**Time Domain Neural Audio Style Transfer**

- intro: NIPS 2017
- arxiv: [https://arxiv.org/abs/1711.11160](https://arxiv.org/abs/1711.11160)
- github: [https://github.com//pkmital/time-domain-neural-audio-style-transfer](https://github.com//pkmital/time-domain-neural-audio-style-transfer)

**Learning Linear Transformations for Fast Arbitrary Style Transfer**

[https://arxiv.org/abs/1808.04537](https://arxiv.org/abs/1808.04537)

## Neural Art On Video

**neural-style-video**

- blog: [http://larseidnes.com/2015/12/18/painting-videos-with-neural-networks/](http://larseidnes.com/2015/12/18/painting-videos-with-neural-networks/)
- github: [https://github.com/larspars/neural-style-video](https://github.com/larspars/neural-style-video)

**Instructions for making a Neural-Style movie**

- website: [https://gist.github.com/genekogan/d61c8010d470e1dbe15d](https://gist.github.com/genekogan/d61c8010d470e1dbe15d)
- sample: [https://vimeo.com/139123754](https://vimeo.com/139123754)

**Artistic style transfer for videos**

- arxiv: [http://arxiv.org/abs/1604.08610](http://arxiv.org/abs/1604.08610)
- github: [https://github.com/manuelruder/artistic-videos](https://github.com/manuelruder/artistic-videos)

**Artistic style transfer for videos and spherical images**

[https://arxiv.org/abs/1708.04538](https://arxiv.org/abs/1708.04538)

**How Deep Learning Can Paint Videos in the Style of Art’s Great Masters**

![](https://blogs.nvidia.com/wp-content/uploads/2016/05/artistic-video-1200x528.jpg)

- blog: [https://blogs.nvidia.com/blog/2016/05/25/deep-learning-paints-videos/](https://blogs.nvidia.com/blog/2016/05/25/deep-learning-paints-videos/)

**DeepMovie: Using Optical Flow and Deep Neural Networks to Stylize Movies**

- arxiv: [http://arxiv.org/abs/1605.08153](http://arxiv.org/abs/1605.08153)

**Coherent Online Video Style Transfer**

[https://arxiv.org/abs/1703.09211](https://arxiv.org/abs/1703.09211)

**Laplacian-Steered Neural Style Transfer**

- intro: ACM Multimedia Conference (MM) 2017
- arxiv: [https://arxiv.org/abs/1707.01253](https://arxiv.org/abs/1707.01253)

**Real-Time Neural Style Transfer for Videos**

- intro: Tsinghua University & Tencent AI Lab
- paper: [http://openaccess.thecvf.com/content_cvpr_2017/papers/Huang_Real-Time_Neural_Style_CVPR_2017_paper.pdf](http://openaccess.thecvf.com/content_cvpr_2017/papers/Huang_Real-Time_Neural_Style_CVPR_2017_paper.pdf)

**Multi-Content GAN for Few-Shot Font Style Transfer**

[https://arxiv.org/abs/1712.00516](https://arxiv.org/abs/1712.00516)

**ReCoNet: Real-time Coherent Video Style Transfer Network**

- intro: The University of Hong Kong
- arixv: [https://arxiv.org/abs/1807.01197](https://arxiv.org/abs/1807.01197)
- supp: [https://www.dropbox.com/s/go6f7uopjjsala7/ReCoNet%20Supplementary%20Material.pdf?dl=0](https://www.dropbox.com/s/go6f7uopjjsala7/ReCoNet%20Supplementary%20Material.pdf?dl=0)

## Neural Doodle

**Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks**

- paper: [http://nucl.ai/semantic-style-transfer.pdf](http://nucl.ai/semantic-style-transfer.pdf)
- reddit: [https://www.reddit.com/r/MachineLearning/comments/48zstj/my_wip_implementation_of_neural_image_analogies/](https://www.reddit.com/r/MachineLearning/comments/48zstj/my_wip_implementation_of_neural_image_analogies/)
- github: [https://github.com/alexjc/neural-doodle](https://github.com/alexjc/neural-doodle)

**Neural Doodle**

![](https://raw.githubusercontent.com/alexjc/neural-doodle/master/docs/Workflow.gif)
![](https://raw.githubusercontent.com/alexjc/neural-doodle/master/docs/Landscape_example.png)

- github: [https://github.com/alexjc/neural-doodle](https://github.com/alexjc/neural-doodle)

**Faster neural doodle**

![](https://raw.githubusercontent.com/DmitryUlyanov/fast-neural-doodle/master/data/Renoir/grid.png)

- github: [https://github.com/DmitryUlyanov/fast-neural-doodle](https://github.com/DmitryUlyanov/fast-neural-doodle)

**Feed-forward neural doodle**

![](https://raw.githubusercontent.com/DmitryUlyanov/online-neural-doodle/master/data/starry/grid.png)

- blog: [http://dmitryulyanov.github.io/feed-forward-neural-doodle/](http://dmitryulyanov.github.io/feed-forward-neural-doodle/)
- github: [https://github.com/DmitryUlyanov/online-neural-doodle](https://github.com/DmitryUlyanov/online-neural-doodle)
- demo: [http://likemo.net/](http://likemo.net/)

**neural image analogies: Generate image analogies using neural matching and blending**

![](https://raw.githubusercontent.com/awentzonline/image-analogies/master/examples/images/sugarskull-analogy.jpg)

- github: [https://github.com/awentzonline/image-analogies](https://github.com/awentzonline/image-analogies)

**Neural doodle with Keras**

[https://github.com/fchollet/keras/blob/master/examples/neural_doodle.py](https://github.com/fchollet/keras/blob/master/examples/neural_doodle.py)

## Deep Dreams

**deepdream**

- github: [https://github.com/google/deepdream](https://github.com/google/deepdream)

**cnn-vis: Use CNNs to generate images**

- github: [https://github.com/jcjohnson/cnn-vis](https://github.com/jcjohnson/cnn-vis)

**bat-country: A lightweight, extendible, easy to use Python package for deep dreaming and image generation with Caffe and CNNs**

- github: [https://github.com/jrosebr1/bat-country](https://github.com/jrosebr1/bat-country)

**DeepDreaming with TensorFlow**

- ipn: [http://nbviewer.jupyter.org/github/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb](http://nbviewer.jupyter.org/github/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb)

**deepdraw**

- github: [https://github.com/auduno/deepdraw](https://github.com/auduno/deepdraw)

**Understanding Deep Dreams**

- blog: [http://www.alanzucconi.com/2015/07/06/live-your-deepdream-how-to-recreate-the-inceptionism-effect/](http://www.alanzucconi.com/2015/07/06/live-your-deepdream-how-to-recreate-the-inceptionism-effect/)

**Generating Deep Dreams**

- blog：[http://www.alanzucconi.com/2016/05/25/generating-deep-dreams/](http://www.alanzucconi.com/2016/05/25/generating-deep-dreams/)

**Audio Deepdream: Optimizing Raw Audio With Convolutional Networks**

- intro: Google Brain
- paper: [https://wp.nyu.edu/ismir2016/wp-content/uploads/sites/2294/2016/08/ardila-audio.pdf](https://wp.nyu.edu/ismir2016/wp-content/uploads/sites/2294/2016/08/ardila-audio.pdf)
- examples: [https://drive.google.com/drive/folders/0B7NUtSSG_AgqZWF1ajdhSjhEMlk](https://drive.google.com/drive/folders/0B7NUtSSG_AgqZWF1ajdhSjhEMlk)

## Emoji

**Brewing EmojiNet**

![](http://engineering.curalate.com/assets/2016-01-13-Emojinet/demo02.png)

- blog: [http://engineering.curalate.com/2016/01/20/emojinet.html](http://engineering.curalate.com/2016/01/20/emojinet.html)
- website: [https://emojini.curalate.com/](https://emojini.curalate.com/)

**Image2Emoji: Zero-shot Emoji Prediction for Visual Media**

- paper: [http://isis-data.science.uva.nl/cgmsnoek/pub/cappallo-image2emoji-mm2015.pdf](http://isis-data.science.uva.nl/cgmsnoek/pub/cappallo-image2emoji-mm2015.pdf)

**Teaching Robots to Feel: Emoji & Deep Learning 👾 💭 💕**

![](http://getdango.com/postimg/RNN-figure.png)

- blog: [http://getdango.com/emoji-and-deep-learning.html](http://getdango.com/emoji-and-deep-learning.html)
- app: [https://play.google.com/store/apps/details?id=co.dango.emoji.gif](https://play.google.com/store/apps/details?id=co.dango.emoji.gif)

**Text input with relevant emoji sorted with deeplearning**

- homepage: [http://codepen.io/Idlework/pen/xOgGqM](http://codepen.io/Idlework/pen/xOgGqM)

## Sketch

**Sketch-a-Net that Beats Humans**

![](/assets/fun_with_dl/Sketch-a-Net_that_Beats_Humans.png)

- project page: [http://www.eecs.qmul.ac.uk/~tmh/downloads.html](http://www.eecs.qmul.ac.uk/~tmh/downloads.html)
- arxiv: [http://arxiv.org/abs/1501.07873](http://arxiv.org/abs/1501.07873)
- paper: [http://www.eecs.qmul.ac.uk/~tmh/papers/yu2015sketchanet.pdf](http://www.eecs.qmul.ac.uk/~tmh/papers/yu2015sketchanet.pdf)
- code: [http://www.eecs.qmul.ac.uk/~tmh/downloads/SketchANet_Code.zip](http://www.eecs.qmul.ac.uk/~tmh/downloads/SketchANet_Code.zip)

**How Do Humans Sketch Objects?**

![](http://cybertron.cg.tu-berlin.de/eitz/projects/classifysketch/teaser_siggraph.jpg)

- project page: [http://cybertron.cg.tu-berlin.de/eitz/projects/classifysketch/](http://cybertron.cg.tu-berlin.de/eitz/projects/classifysketch/)
- paper: [http://cybertron.cg.tu-berlin.de/eitz/pdf/2012_siggraph_classifysketch.pdf](http://cybertron.cg.tu-berlin.de/eitz/pdf/2012_siggraph_classifysketch.pdf)
- github: [https://github.com/Zebreu/SketchingAI](https://github.com/Zebreu/SketchingAI)
- gitxiv: [http://gitxiv.com/posts/ZBCxEc9g3Fg5xCQ6n/sketchingai](http://gitxiv.com/posts/ZBCxEc9g3Fg5xCQ6n/sketchingai)

**Learning to Simplify: Fully Convolutional Networks for Rough Sketch Cleanup (SIGGRAPH 2016)**

![](http://hi.cs.waseda.ac.jp/~esimo/images/sketch/overview.png)

- homepage: [http://hi.cs.waseda.ac.jp/~esimo/en/research/sketch/](http://hi.cs.waseda.ac.jp/~esimo/en/research/sketch/)
- paper: [http://hi.cs.waseda.ac.jp/~esimo/publications/SimoSerraSIGGRAPH2016.pdf](http://hi.cs.waseda.ac.jp/~esimo/publications/SimoSerraSIGGRAPH2016.pdf)

**Convolutional Sketch Inversion**

![](/assets/fun_with_dl/Convolutional_Sketch_Inversion.png)

- arxiv: [http://arxiv.org/abs/1606.03073](http://arxiv.org/abs/1606.03073)
- review: [https://www.technologyreview.com/s/601684/machine-vision-algorithm-learns-to-transform-hand-drawn-sketches-into-photorealistic-images/](https://www.technologyreview.com/s/601684/machine-vision-algorithm-learns-to-transform-hand-drawn-sketches-into-photorealistic-images/)
- review: [https://techcrunch.com/2016/07/24/researchers-use-neural-networks-to-turn-face-sketches-into-photos/](https://techcrunch.com/2016/07/24/researchers-use-neural-networks-to-turn-face-sketches-into-photos/)

**Sketch Me That Shoe (CVPR 2016)**

![](http://www.eecs.qmul.ac.uk/~qian/Qian's%20Materials/0001.jpg)

- project page: [http://www.eecs.qmul.ac.uk/~qian/Project_cvpr16.html](http://www.eecs.qmul.ac.uk/~qian/Project_cvpr16.html)
- paper: [http://www.eecs.qmul.ac.uk/~qian/SketchMeThatShoe.pdf](http://www.eecs.qmul.ac.uk/~qian/SketchMeThatShoe.pdf)
- github: [https://github.com/seuliufeng/DeepSBIR](https://github.com/seuliufeng/DeepSBIR)

**Mastering Sketching: Adversarial Augmentation for Structured Prediction**

- keywords: Sketch Simplification
- project page: [http://hi.cs.waseda.ac.jp/~esimo/en/research/sketch_master/](http://hi.cs.waseda.ac.jp/~esimo/en/research/sketch_master/)
- arxiv: [https://arxiv.org/abs/1703.08966](https://arxiv.org/abs/1703.08966)
- github: [https://github.com/bobbens/sketch_simplification](https://github.com/bobbens/sketch_simplification)

**SketchyGAN: Towards Diverse and Realistic Sketch to Image Synthesis**

- intro: Georgia Institute of Technology
- arxiv: [https://arxiv.org/abs/1801.02753](https://arxiv.org/abs/1801.02753)

## Image Stylization

**Automatic Portrait Segmentation for Image Stylization**

![](http://xiaoyongshen.me/webpage_portrait/figures/teaser.png)

- intro: The Chinese University of Hong Kong & Adobe Research
- project page(data+code): [http://xiaoyongshen.me/webpage_portrait/index.html](http://xiaoyongshen.me/webpage_portrait/index.html)
- paper: [http://www.cse.cuhk.edu.hk/leojia/papers/portrait_eg16.pdf](http://www.cse.cuhk.edu.hk/leojia/papers/portrait_eg16.pdf)
- github(Tensorflow): [https://github.com/PetroWu/AutoPortraitMatting](https://github.com/PetroWu/AutoPortraitMatting)

**Transfiguring Portraits**

![](/assets/fun_with_dl/Transfiguring_Portraits.jpg)

- paper: [http://homes.cs.washington.edu/~kemelmi/Transfiguring_Portraits_Kemelmacher_SIGGRAPH2016.pdf](http://homes.cs.washington.edu/~kemelmi/Transfiguring_Portraits_Kemelmacher_SIGGRAPH2016.pdf)

**Stylize Aesthetic QR Code**

- intro: Zhengzhou University & Zhejiang University
- arxiv: [https://arxiv.org/abs/1803.01146](https://arxiv.org/abs/1803.01146)

## Image Colorization

**Deep Colorization**

- paper: [http://www.cs.cityu.edu.hk/~qiyang/publications/iccv-15.pdf](http://www.cs.cityu.edu.hk/~qiyang/publications/iccv-15.pdf)

**Learning Large-Scale Automatic Image Colorization**

- paper: [http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Deshpande_Learning_Large-Scale_Automatic_ICCV_2015_paper.pdf](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Deshpande_Learning_Large-Scale_Automatic_ICCV_2015_paper.pdf)

**Learning Representations for Automatic Colorization**

![](http://people.cs.uchicago.edu/~larsson/colorization/overview.png)

- homepage: [http://people.cs.uchicago.edu/~larsson/colorization/](http://people.cs.uchicago.edu/~larsson/colorization/)
- arxiv: [http://arxiv.org/abs/1603.06668](http://arxiv.org/abs/1603.06668)
- github: [https://github.com/gustavla/autocolorize](https://github.com/gustavla/autocolorize)

**Colorful Image Colorization**

![](http://richzhang.github.io/colorization/resources/images/net_diagram.jpg)

- intro: ECCV 2016
- project page: [http://richzhang.github.io/colorization/](http://richzhang.github.io/colorization/)
- arxiv: [http://arxiv.org/abs/1603.08511](http://arxiv.org/abs/1603.08511)
- github: [https://github.com/richzhang/colorization](https://github.com/richzhang/colorization)
- demo: [http://demos.algorithmia.com/colorize-photos/](http://demos.algorithmia.com/colorize-photos/)
- github: [https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/Colorful](https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/Colorful)
 github(Tensorflow): [https://github.com/nilboy/colorization-tf](https://github.com/nilboy/colorization-tf)

 **Colorising Black & White Photos using Deep Learning**

 [https://hackernoon.com/colorising-black-white-photos-using-deep-learning-4da22a05f531](https://hackernoon.com/colorising-black-white-photos-using-deep-learning-4da22a05f531)

 - - -

**Automatic Colorization (Tensorflow + VGG)**

![](http://tinyclouds.org/colorize/best/6.jpg)

- blog: [http://tinyclouds.org/colorize/](http://tinyclouds.org/colorize/)

**colornet: Neural Network to colorize grayscale images**

[https://github.com/pavelgonchar/colornet](https://github.com/pavelgonchar/colornet)

**Let there be Color!: Joint End-to-end Learning of Global and Local Image Priors for Automatic Image Colorization with Simultaneous Classification (SIGGRAPH 2016)**

![](http://hi.cs.waseda.ac.jp/~iizuka/projects/colorization/images/model.png)

- homepage: [http://hi.cs.waseda.ac.jp/~iizuka/projects/colorization/](http://hi.cs.waseda.ac.jp/~iizuka/projects/colorization/)
- paper: [http://hi.cs.waseda.ac.jp/~iizuka/projects/colorization/data/colorization_sig2016.pdf](http://hi.cs.waseda.ac.jp/~iizuka/projects/colorization/data/colorization_sig2016.pdf)
- github(Torch7): [https://github.com/satoshiiizuka/siggraph2016_colorization](https://github.com/satoshiiizuka/siggraph2016_colorization)

**Convolutional autoencoder to colorize greyscale images**

- github: [https://github.com/YerevaNN/neural-colorizer](https://github.com/YerevaNN/neural-colorizer)

**Image-Color: A deep learning approach to colorizing images**

- github: [https://github.com/cameronfabbri/Colorful-Image-Colorization](https://github.com/cameronfabbri/Colorful-Image-Colorization)

**Creating an artificial artist: Color your photos using Neural Networks**

- blog: [https://www.analyticsvidhya.com/blog/2016/11/creating-an-artificial-artist-color-your-photos-using-neural-networks/](https://www.analyticsvidhya.com/blog/2016/11/creating-an-artificial-artist-color-your-photos-using-neural-networks/)

**Paints Chainer: line drawing colorization using chainer**

- github: [https://github.com/pfnet/PaintsChainer](https://github.com/pfnet/PaintsChainer)
- demo: [http://paintschainer.preferred.tech/](http://paintschainer.preferred.tech/)

**Unsupervised Diverse Colorization via Generative Adversarial Networks**

- arxiv: [https://arxiv.org/abs/1702.06674](https://arxiv.org/abs/1702.06674)

**(DE)^2 CO: Deep Depth Colorization**

[https://arxiv.org/abs/1703.10881](https://arxiv.org/abs/1703.10881)

**A Neural Representation of Sketch Drawings**

- intro: Google Brain
- arxiv: [https://arxiv.org/abs/1704.03477](https://arxiv.org/abs/1704.03477)

**Real-Time User-Guided Image Colorization with Learned Deep Priors**

- intro: SIGGRAPH 2017
- project page: [https://richzhang.github.io/ideepcolor/](https://richzhang.github.io/ideepcolor/)
- arxiv: [https://arxiv.org/abs/1705.02999](https://arxiv.org/abs/1705.02999)
- github(official, Caffe): [https://github.com/junyanz/interactive-deep-colorization](https://github.com/junyanz/interactive-deep-colorization)

**PixColor: Pixel Recursive Colorization**

- intro: Google Research
- arxiv: [https://arxiv.org/abs/1705.07208](https://arxiv.org/abs/1705.07208)

**cGAN-based Manga Colorization Using a Single Training Image**

- intro: University of Tokyo
- arxiv: [https://arxiv.org/abs/1706.06918](https://arxiv.org/abs/1706.06918)

**Interactive Deep Colorization With Simultaneous Global and Local Inputs**

[https://arxiv.org/abs/1801.09083](https://arxiv.org/abs/1801.09083)

**Image Colorization with Generative Adversarial Networks**

[https://arxiv.org/abs/1803.05400](https://arxiv.org/abs/1803.05400)

**Learning to Color from Language**

- intro: Allen Institute of Artificial Intelligence & University of Massachusetts
- arxiv: [https://arxiv.org/abs/1804.06026](https://arxiv.org/abs/1804.06026)

**Deep Exemplar-based Colorization**

- intro: Siggraph 2018
- arxiv: [https://arxiv.org/abs/1807.06587](https://arxiv.org/abs/1807.06587)

**Pixel-level Semantics Guided Image Colorization**

[https://arxiv.org/abs/1808.01597](https://arxiv.org/abs/1808.01597)

**User-Guided Deep Anime Line Art Colorization with Conditional Adversarial Networks**

- intro: 2018 ACM Multimedia Conference (MM '18)
- arxiv: [https://arxiv.org/abs/1808.03240](https://arxiv.org/abs/1808.03240)

# Sounds

**Visually Indicated Sounds**

![](http://vis.csail.mit.edu/pipeline.jpg)

- project page: [http://vis.csail.mit.edu/](http://vis.csail.mit.edu/)
- arxiv: [http://arxiv.org/abs/1512.08512](http://arxiv.org/abs/1512.08512)

# Music

**GRUV: Algorithmic Music Generation using Recurrent Neural Networks**

- github: [https://github.com/MattVitelli/GRUV](https://github.com/MattVitelli/GRUV)

**DeepHear - Composing and harmonizing music with neural networks**

- website: [http://web.mit.edu/felixsun/www/neural-music.html](http://web.mit.edu/felixsun/www/neural-music.html)
- github: [https://github.com/fephsun/neuralnetmusic](https://github.com/fephsun/neuralnetmusic)

**Using AutoHarp and a Character-Based RNN to Create MIDI Drum Loops**

- website: [http://www.inquisitivists.com/2015/09/16/using-autoharp-and-a-character-based-rnn-to-create-midi-drum-loops](http://www.inquisitivists.com/2015/09/16/using-autoharp-and-a-character-based-rnn-to-create-midi-drum-loops)

**Musical Audio Synthesis Using Autoencoding Neural Nets**

- paper: [http://www.cs.dartmouth.edu/~sarroff/papers/sarroff2014a.pdf](http://www.cs.dartmouth.edu/~sarroff/papers/sarroff2014a.pdf)
- github: [https://github.com/woodshop/deepAutoController/tree/icmc_smc_2014](https://github.com/woodshop/deepAutoController/tree/icmc_smc_2014)
- video: [https://vimeo.com/121827215](https://vimeo.com/121827215)

**sound-rnn: Generating sound using recurrent neural networks**

- github: [https://github.com/johnglover/sound-rnn](https://github.com/johnglover/sound-rnn)
- blog: [http://www.johnglover.net/blog/generating-sound-with-rnns.html](http://www.johnglover.net/blog/generating-sound-with-rnns.html)

**Using LSTM Recurrent Neural Networks for Music Generation (Project for AI Prac Fall 2015 at Cornell)**

- youtube: [https://www.youtube.com/watch?v=aSr8_QQYpYM](https://www.youtube.com/watch?v=aSr8_QQYpYM)
- video: [http://video.weibo.com/show?fid=1034:4be01d679bb1a68a634fe0f589caa779](http://video.weibo.com/show?fid=1034:4be01d679bb1a68a634fe0f589caa779)

**Visually Indicated Sounds (MIT. 2015)**

- arxiv: [http://arxiv.org/abs/1512.08512](http://arxiv.org/abs/1512.08512)

**Training a Recurrent Neural Network to Compose Music**

- blog: [https://maraoz.com/2016/02/02/abc-rnn/](https://maraoz.com/2016/02/02/abc-rnn/)

**LSTM Realbook**

![](https://keunwoochoi.files.wordpress.com/2016/02/band-in-a-box-195117-2.jpeg?w=788&h=474)

- blog: [https://keunwoochoi.wordpress.com/2016/02/19/lstm-realbook/](https://keunwoochoi.wordpress.com/2016/02/19/lstm-realbook/)
- github: [https://github.com/keunwoochoi/lstm_real_book](https://github.com/keunwoochoi/lstm_real_book)

**LSTMetallica: Generation drum tracks by learning the drum tracks of 60 Metallica songs**

- blog: [https://keunwoochoi.wordpress.com/2016/02/23/lstmetallica/](https://keunwoochoi.wordpress.com/2016/02/23/lstmetallica/)

**deepjazz: Deep learning driven jazz generation using Keras & Theano!**

- homepage: [https://jisungk.github.io/deepjazz/](https://jisungk.github.io/deepjazz/)
- github：[https://github.com/jisungk/deepjazz](https://github.com/jisungk/deepjazz)

**Magenta: Music and Art Generation with Machine Intelligence**

- homepage: [http://magenta.tensorflow.org/](http://magenta.tensorflow.org/)
- github: [https://github.com/tensorflow/magenta](https://github.com/tensorflow/magenta)

**Music Transcription with Convolutional Neural Networks**

- blog: [https://www.lunaverus.com/cnn](https://www.lunaverus.com/cnn)
- download: [https://www.lunaverus.com/download](https://www.lunaverus.com/download)

**Long Short-Term Memory Recurrent Neural Network Architectures for Generating Music and Japanese Lyrics**

- paper: [http://cslab1.bc.edu/~csacademics/pdf/16Mikami.pdf](http://cslab1.bc.edu/~csacademics/pdf/16Mikami.pdf)
- github: [https://github.com/mikamia](https://github.com/mikamia)

**BachBot: Use deep learning to generate and harmonize music in the style of Bach**

- intro: BachBot is a research project utilizing long short term memory (LSTMs) to generate Bach compositions
- homepage: [http://bachbot.com/](http://bachbot.com/)
- github: [https://github.com/feynmanliang/bachbot](https://github.com/feynmanliang/bachbot)

**Generate Music in TensorFlow**

- youtube: [https://www.youtube.com/watch?v=ZE7qWXX05T0](https://www.youtube.com/watch?v=ZE7qWXX05T0)
- github: [https://github.com/llSourcell/Music_Generator_Demo](https://github.com/llSourcell/Music_Generator_Demo)

**Generate new lyrics in the style of any artist using LSTMs and TensorFlow**

- github: [https://github.com/dyelax/encore.ai](https://github.com/dyelax/encore.ai)

**sound-GAN: Generative Adversial Network for music composition**

- github: [https://github.com/jacotar/sound-GAN](https://github.com/jacotar/sound-GAN)

**Analyzing Six Deep Learning Tools for Music Generation**

- intro: Magenta / DeepJazz / BachBot / FlowMachines / WaveNet / GRUV
- blog: [http://www.asimovinstitute.org/notes-vs-waves/](http://www.asimovinstitute.org/notes-vs-waves/)

**WIMP2: Creating Music with AI: Highlights of Current Research**

- youtube: [https://www.youtube.com/watch?v=5K4hn6cBUPU](https://www.youtube.com/watch?v=5K4hn6cBUPU)

**Song From PI: A Musically Plausible Network for Pop Music Generation**

- paper: [http://openreview.net/pdf?id=ByBwSPcex](http://openreview.net/pdf?id=ByBwSPcex)
- project page: [http://www.cs.toronto.edu/songfrompi/](http://www.cs.toronto.edu/songfrompi/)

**Grammar Argumented LSTM Neural Networks with Note-Level Encoding for Music Composition**

- arxiv: [https://arxiv.org/abs/1611.05416](https://arxiv.org/abs/1611.05416)

**用TensorFlow生成周杰伦歌词**

- blog: [http://leix.me/2016/11/28/tensorflow-lyrics-generation/](http://leix.me/2016/11/28/tensorflow-lyrics-generation/)
- github: [https://github.com/leido/char-rnn-cn](https://github.com/leido/char-rnn-cn)

**Hip-Hop - Generating lyrics with RNNs**

- blog: [http://affinelayer.com/hiphop/index.html](http://affinelayer.com/hiphop/index.html)

**Metis Final Project: Music Composition with LSTMs**

[http://blog.naoya.io/metis-final-project-music-composition-with-lstms/](http://blog.naoya.io/metis-final-project-music-composition-with-lstms/)

**Neural Translation of Musical Style**

- blog: [http://imanmalik.com/cs/2017/06/05/neural-style.html](http://imanmalik.com/cs/2017/06/05/neural-style.html)
- github: [https://github.com/imalikshake/StyleNet](https://github.com/imalikshake/StyleNet)

# Poetry

**NeuralSnap: Generates poetry from images using convolutional and recurrent neural networks**

- github: [https://github.com/rossgoodwin/neuralsnap](https://github.com/rossgoodwin/neuralsnap)

**Generating Chinese Classical Poems with RNN Encoder-Decoder**

- arxiv: [http://arxiv.org/abs/1604.01537](http://arxiv.org/abs/1604.01537)

**Chinese Poetry Generation with Planning based Neural Network**

- intro: COLING 2016. University of Science and Technology of China & Baidu
- arxiv: [https://arxiv.org/abs/1610.09889](https://arxiv.org/abs/1610.09889)
- blog: [http://freecoder.me/archives/213.html](http://freecoder.me/archives/213.html)

# Weiqi (Go)

**Teaching Deep Convolutional Neural Networks to Play Go**

- arxiv: [http://arxiv.org/abs/1412.3409](http://arxiv.org/abs/1412.3409)
- demo: [https://chrisc36.github.io/deep-go/](https://chrisc36.github.io/deep-go/)

**Move Evaluation in Go Using Deep Convolutional Neural Networks(Google DeepMind, Google Brain)**

- arxiv: [http://arxiv.org/abs/1412.6564](http://arxiv.org/abs/1412.6564)

**Training Deep Convolutional Neural Networks to Play Go**

- paper: [http://jmlr.org/proceedings/papers/v37/clark15.pdf](http://jmlr.org/proceedings/papers/v37/clark15.pdf)

**Computer Go Research - The Challenges Ahead (Martin Müller. IEEE CIG 2015)**

- homepage: [https://webdocs.cs.ualberta.ca/~mmueller/talks.html](https://webdocs.cs.ualberta.ca/~mmueller/talks.html)

**GoCNN: Using CNN for Go (Weiqi/Baduk) board evaluation with tensorflow**

- github: [https://github.com/jmgilmer/GoCNN](https://github.com/jmgilmer/GoCNN)

**DarkGo: Go in Darknet**

- homepage: [http://pjreddie.com/darknet/darkgo-go-in-darknet/](http://pjreddie.com/darknet/darkgo-go-in-darknet/)

**BetaGo: Go bots for the people**

- homepage: [http://maxpumperla.github.io/betago/](http://maxpumperla.github.io/betago/)
- github: [https://github.com/maxpumperla/betago](https://github.com/maxpumperla/betago)

**Deep Learning and the Game of Go**

- book: [https://www.manning.com/books/deep-learning-and-the-game-of-go](https://www.manning.com/books/deep-learning-and-the-game-of-go)
- github: [https://github.com//maxpumperla/deep_learning_and_the_game_of_go](https://github.com//maxpumperla/deep_learning_and_the_game_of_go)

## DarkForest

**Better Computer Go Player with Neural Network and Long-term Prediction (Facebook AI Research)**

![](https://raw.githubusercontent.com/facebookresearch/darkforestGo/master/figure.png)

- arxiv: [http://arxiv.org/abs/1511.06410](http://arxiv.org/abs/1511.06410)
- github: [https://github.com/facebookresearch/darkforestGo](https://github.com/facebookresearch/darkforestGo)
- MIT tech review: [http://www.technologyreview.com/view/544181/how-facebooks-ai-researchers-built-a-game-changing-go-engine/](http://www.technologyreview.com/view/544181/how-facebooks-ai-researchers-built-a-game-changing-go-engine/)

## AlphaGo

**Mastering the game of Go with deep neural networks and tree search**

![](http://k.sinaimg.cn/n/sports/transform/20160128/RGVK-fxnzanh0214327.jpg/w570778.jpg)

- intro: AlphaGo. Google DeepMind
- homepage: [http://www.deepmind.com/alpha-go.html](http://www.deepmind.com/alpha-go.html)
- paper: [https://storage.googleapis.com/deepmind-data/assets/papers/deepmind-mastering-go.pdf](https://storage.googleapis.com/deepmind-data/assets/papers/deepmind-mastering-go.pdf)
- naturep page: [http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html](http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html)
- paper: [https://gogameguru.com/i/2016/03/deepmind-mastering-go.pdf](https://gogameguru.com/i/2016/03/deepmind-mastering-go.pdf)
- slides: [http://www.bioinfo.org.cn/~casp/temp/alphago_slides.pdf](http://www.bioinfo.org.cn/~casp/temp/alphago_slides.pdf)
- blog: [http://www.furidamu.org/blog/2016/01/26/mastering-the-game-of-go-with-deep-neural-networks-and-tree-search/](http://www.furidamu.org/blog/2016/01/26/mastering-the-game-of-go-with-deep-neural-networks-and-tree-search/)
- blog("AlphaGo: From Intuitive Learning to Holistic Knowledge"): [https://caminao.wordpress.com/2016/02/01/alphago/](https://caminao.wordpress.com/2016/02/01/alphago/)
- github: [https://github.com/Rochester-NRT/AlphaGo](https://github.com/Rochester-NRT/AlphaGo)

**AlphaGo Teach**

- intro: Let the AlphaGo Teaching Tool help you find new and creative ways of playing Go
- homepage: [https://alphagoteach.deepmind.com/](https://alphagoteach.deepmind.com/)

**AlphaGo的分析**

- intro: by 田渊栋
- blog: [http://zhuanlan.zhihu.com/yuandong/20607684](http://zhuanlan.zhihu.com/yuandong/20607684)

**How Alphago Works**

- slides: [http://www.slideshare.net/ShaneSeungwhanMoon/how-alphago-works](http://www.slideshare.net/ShaneSeungwhanMoon/how-alphago-works)
- slides: [http://pan.baidu.com/s/1qXwagGW](http://pan.baidu.com/s/1qXwagGW)

**AlphaGo in Depth**

- intro: by Mark Chang
- slides: [http://www.slideshare.net/ckmarkohchang/alphago-in-depth?qid=283ab3bc-7d04-4e14-a205-b0b671ca4099](http://www.slideshare.net/ckmarkohchang/alphago-in-depth?qid=283ab3bc-7d04-4e14-a205-b0b671ca4099)
- mirror: [https://pan.baidu.com/s/1i5JNeRj](https://pan.baidu.com/s/1i5JNeRj)

**Leela**

- intro: Leela is a strong Go playing program combining advances in Go programming and 
further original research into a small, easy to use graphical interface.
- homepage: [https://sjeng.org/leela.html](https://sjeng.org/leela.html)

**Mastering the game of Go without human knowledge**

- nature page: [http://www.nature.com/nature/journal/v550/n7676/full/nature24270.html](http://www.nature.com/nature/journal/v550/n7676/full/nature24270.html)
- paper: [https://deepmind.com/documents/119/agz_unformatted_nature.pdf](https://deepmind.com/documents/119/agz_unformatted_nature.pdf)
- notes: [https://blog.acolyer.org/2017/11/17/mastering-the-game-of-go-without-human-knowledge/](https://blog.acolyer.org/2017/11/17/mastering-the-game-of-go-without-human-knowledge/)

**Computer Go & AlphaGo Zero**

- youtube: [https://www.youtube.com/watch?v=6fKG4wJ7uBk](https://www.youtube.com/watch?v=6fKG4wJ7uBk)
- mirror: [https://www.bilibili.com/video/av16428694/](https://www.bilibili.com/video/av16428694/)
- slides: [https://drive.google.com/file/d/1rmUyIitEmAtMUKdKEnlHRfmXtpyoxxey/view](https://drive.google.com/file/d/1rmUyIitEmAtMUKdKEnlHRfmXtpyoxxey/view)

**AlphaZero: Mastering Games without Human Knowledge - NIPS 2017**

- intro: Keynote by David Silver on AlphaGo, AlphaGo Zero and AlphaZero, at the 2017 NIPS Deep Reinforcement Learning Symposium, 6 Dec, Long Beach, CA
- youtube: [https://www.youtube.com/watch?v=A3ekFcZ3KNw](https://www.youtube.com/watch?v=A3ekFcZ3KNw)
- mirror: [https://www.bilibili.com/video/av17210816/](https://www.bilibili.com/video/av17210816/)

**PhoenixGo**

- intro: Go AI program which implement the AlphaGo Zero paper
- github: [https://github.com/Tencent/PhoenixGo](https://github.com/Tencent/PhoenixGo)

**The future is here – AlphaZero learns chess**

[https://en.chessbase.com/post/the-future-is-here-alphazero-learns-chess](https://en.chessbase.com/post/the-future-is-here-alphazero-learns-chess)

**AlphaGo Zero Cheat Sheet**

[https://applied-data.science/static/main/res/alpha_go_zero_cheat_sheet.png](https://applied-data.science/static/main/res/alpha_go_zero_cheat_sheet.png)

# Chess

**Giraffe: Using Deep Reinforcement Learning to Play Chess**

- intro: MSc thesis
- arxiv: [http://arxiv.org/abs/1509.01549](http://arxiv.org/abs/1509.01549)

**Spawkfish: neural network based chess engine**

- homepage: [http://spawk.fish/](http://spawk.fish/)

**Chess position evaluation with convolutional neural network in Julia**

- blog: [http://int8.io/chess-position-evaluation-with-convolutional-neural-networks-in-julia/](http://int8.io/chess-position-evaluation-with-convolutional-neural-networks-in-julia/)

**Deep Learning for ... Chess**

- blog: [http://blog.yhat.com/posts/deep-learning-chess.html](http://blog.yhat.com/posts/deep-learning-chess.html)
- github: [https://github.com/erikbern/deep-pink](https://github.com/erikbern/deep-pink)

**DeepChess: End-to-End Deep Neural Network for Automatic Learning in Chess**

- intro: Winner of Best Paper Award in ICANN 2016
- arxiv: [https://arxiv.org/abs/1711.09667](https://arxiv.org/abs/1711.09667)
- paper: [http://www.cs.tau.ac.il/~wolf/papers/deepchess.pdf](http://www.cs.tau.ac.il/~wolf/papers/deepchess.pdf)
- github: [https://github.com/mr-press/DeepChess](https://github.com/mr-press/DeepChess)

**Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm**

- intro: DeepMind
- arxiv: [https://arxiv.org/abs/1712.01815](https://arxiv.org/abs/1712.01815)

# Game

**Learning Game of Life with a Convolutional Neural Network**

- blog: [http://danielrapp.github.io/cnn-gol/](http://danielrapp.github.io/cnn-gol/)
- github: [https://github.com/DanielRapp/cnn-gol](https://github.com/DanielRapp/cnn-gol)

**Reinforcement Learning using Tensor Flow: A deep Q learning demonstration using Google Tensorflow**

![](https://raw.githubusercontent.com/nivwusquorum/tensorflow-deepq/master/data/example.gif)

- github: [https://github.com/nivwusquorum/tensorflow-deepq](https://github.com/nivwusquorum/tensorflow-deepq)

**Poker-CNN: A Pattern Learning Strategy for Making Draws and Bets in Poker Games Using Convolutional Networks**

- arxiv: [http://arxiv.org/abs/1509.06731](http://arxiv.org/abs/1509.06731)
- paper: [http://colinraffel.com/publications/aaai2016poker.pdf](http://colinraffel.com/publications/aaai2016poker.pdf)
- github: [https://github.com/moscow25/deep_draw](https://github.com/moscow25/deep_draw)
- slides: [https://drive.google.com/file/d/0B5eOIUHA0khiMjN1YnEtZHMwams/view](https://drive.google.com/file/d/0B5eOIUHA0khiMjN1YnEtZHMwams/view)
- slides: [http://pan.baidu.com/s/1nu5zpZ7](http://pan.baidu.com/s/1nu5zpZ7)

**TorchCraft: a Library for Machine Learning Research on Real-Time Strategy Games**

- intro: Connecting Torch to StarCraft
- arxiv: [https://arxiv.org/abs/1611.00625](https://arxiv.org/abs/1611.00625)
- github: [https://github.com/TorchCraft/TorchCraft](https://github.com/TorchCraft/TorchCraft)

**BlizzCon 2016 DeepMind and StarCraft II Deep Learning Panel Transcript**

- part 1: [http://starcraft.blizzplanet.com/blog/comments/blizzcon-2016-deepmind-and-starcraft-ii-deep-learning-panel-transcript](http://starcraft.blizzplanet.com/blog/comments/blizzcon-2016-deepmind-and-starcraft-ii-deep-learning-panel-transcript)
- part 2: [http://starcraft.blizzplanet.com/blog/comments/blizzcon-2016-deepmind-and-starcraft-ii-deep-learning-panel-transcript/2](http://starcraft.blizzplanet.com/blog/comments/blizzcon-2016-deepmind-and-starcraft-ii-deep-learning-panel-transcript/2)

**DeepStack: Expert-Level Artificial Intelligence in No-Limit Poker**

- arxiv: [https://arxiv.org/abs/1701.01724](https://arxiv.org/abs/1701.01724)
- github: [https://github.com/lifrordi/DeepStack-Leduc](https://github.com/lifrordi/DeepStack-Leduc)

**Gym StarCraft: StarCraft environment for OpenAI Gym, based on Facebook's TorchCraft**

- intro: Gym StarCraft is an environment bundle for OpenAI Gym. 
It is based on Facebook's TorchCraft, which is a bridge between Torch and StarCraft for AI research.
- github: [https://github.com/deepcraft/gym-starcraft](https://github.com/deepcraft/gym-starcraft)

**Multiagent Bidirectionally-Coordinated Nets for Learning to Play StarCraft Combat Games**

[https://arxiv.org/abs/1703.10069](https://arxiv.org/abs/1703.10069)

**Learning Macromanagement in StarCraft from Replays using Deep Learning**

- intro: CIG 2017. IT University of Copenhagen
- arxiv: [https://arxiv.org/abs/1707.03743](https://arxiv.org/abs/1707.03743)

**Multi-platform Version of StarCraft: Brood War in a Docker Container: Technical Report**

- intro: Czech Technical University in Prague
- arxiv: [https://arxiv.org/abs/1801.02193](https://arxiv.org/abs/1801.02193)
- gihtub: [https://github.com/Games-and-Simulations/sc-docker](https://github.com/Games-and-Simulations/sc-docker)

**Macro action selection with deep reinforcement learning in StarCraft**

- intro: Bilibili & Nanjing University
- arxiv: [https://arxiv.org/abs/1812.00336](https://arxiv.org/abs/1812.00336)
- github: [https://github.com/Bilibili/LastOrder](https://github.com/Bilibili/LastOrder)

## DeepLeague

**DeepLeague: leveraging computer vision and deep learning on the League of Legends mini map + giving away a dataset of over 100,000 labeled images to further esports analytics research**

- blog: [https://medium.com/@farzatv/deepleague-leveraging-computer-vision-and-deep-learning-on-the-league-of-legends-mini-map-giving-d275fd17c4e0](https://medium.com/@farzatv/deepleague-leveraging-computer-vision-and-deep-learning-on-the-league-of-legends-mini-map-giving-d275fd17c4e0)

**DeepLeague (Part 2): The Technical Details**

- blog: [https://medium.com/@farzatv/deepleague-part-2-the-technical-details-374439e7e09a](https://medium.com/@farzatv/deepleague-part-2-the-technical-details-374439e7e09a)
- github: [https://github.com/farzaa/DeepLeague](https://github.com/farzaa/DeepLeague)

# Courses

**Learning Machines**

[http://www.patrickhebron.com/learning-machines/](http://www.patrickhebron.com/learning-machines/)

**Learning Bit by Bit**

[https://itp.nyu.edu/varwiki/Syllabus/LearningBitbyBitS10](https://itp.nyu.edu/varwiki/Syllabus/LearningBitbyBitS10)

**MACHINE LEARNING FOR MUSICIANS AND ARTISTS (Course opens January 2016)**

[https://www.kadenze.com/courses/machine-learning-for-musicians-and-artists/info](https://www.kadenze.com/courses/machine-learning-for-musicians-and-artists/info)

**Machine learning for artists @ ITP-NYU, Spring 2016**

![](http://www.kdnuggets.com/wp-content/uploads/mona-lisa.jpg)

- videos/lectures/course notes: [http://ml4a.github.io/classes/itp-S16/]([http://ml4a.github.io/classes/itp-S16/])
- index: [http://ml4a.github.io/index/](http://ml4a.github.io/index/)
- github: [https://github.com/ml4a/ml4a.github.io](https://github.com/ml4a/ml4a.github.io)
- notes: [http://www.kdnuggets.com/2016/04/machine-learning-artists-video-lectures-notes.html](http://www.kdnuggets.com/2016/04/machine-learning-artists-video-lectures-notes.html)
- blog: [https://medium.com/@genekogan/machine-learning-for-artists-e93d20fdb097#.25w95beqb](https://medium.com/@genekogan/machine-learning-for-artists-e93d20fdb097#.25w95beqb)

**Machine Learning for Artists @ OpenDot, November 2016**

- homepage: [http://ml4a.github.io/classes/opendot/](http://ml4a.github.io/classes/opendot/)

**The Neural Aesthetic @ SchoolOfMa, Summer 2016**

[http://ml4a.github.io/classes/neural-aesthetic/](http://ml4a.github.io/classes/neural-aesthetic/)

# Blogs

**Review of machine / deep learning in an artistic context**

[https://medium.com/@memoakten/machine-deep-learning-in-an-artistic-context-441f28774bcc#.gegpq99ag](https://medium.com/@memoakten/machine-deep-learning-in-an-artistic-context-441f28774bcc#.gegpq99ag)

**Apprentice Work**

![](https://d267cvn3rvuq91.cloudfront.net/i/images/gayfordx2079.jpg?sw=590&cx=93&cy=28&cw=1892&ch=2522)

[https://www.technologyreview.com/s/600762/apprentice-work/](https://www.technologyreview.com/s/600762/apprentice-work/)

**Exploring the Intersection of Art and Machine Intelligence**

![](https://2.bp.blogspot.com/-RMPIwkAonnI/VstG8b2VZrI/AAAAAAAAA4c/8yYzUt2HF4g/s1600/image02.png)

[http://googleresearch.blogspot.jp/2016/02/exploring-intersection-of-art-and.html](http://googleresearch.blogspot.jp/2016/02/exploring-intersection-of-art-and.html)

**Using machine learning to generate music**

![](http://api.ning.com/files/AOzcN6l-SPr7b3kjg*PpWCTfYlK36W6nG2KcQswQ4YcxWwLfUnqzTUJReEyVoBJtX*4vbP-d19qoLm2TBspkdZ9ZQ40Z1Pb7/maxresdefault.jpg?width=450)

[http://www.datasciencecentral.com/profiles/blogs/using-machine-learning-to-generate-music](http://www.datasciencecentral.com/profiles/blogs/using-machine-learning-to-generate-music)

**art in the age of machine intelligence**

[https://medium.com/artists-and-machine-intelligence/what-is-ami-ccd936394a83#.hyt4ei9a9](https://medium.com/artists-and-machine-intelligence/what-is-ami-ccd936394a83#.hyt4ei9a9)

**Understanding Aesthetics with Deep Learning**

![](https://devblogs.nvidia.com/parallelforall/wp-content/uploads/2016/02/faces_CNNs.jpg)

[https://devblogs.nvidia.com/parallelforall/understanding-aesthetics-deep-learning/](https://devblogs.nvidia.com/parallelforall/understanding-aesthetics-deep-learning/)

**Go, Marvin Minsky, and the Chasm that AI Hasn’t Yet Crossed**

blog: [https://medium.com/backchannel/has-deepmind-really-passed-go-adc85e256bec#.inx8nfid0](https://medium.com/backchannel/has-deepmind-really-passed-go-adc85e256bec#.inx8nfid0)

**A Return to Machine Learning**

- intro: This post is aimed at artists and other creative people who are interested in a survey of recent developments in machine learning research that intersect with art and culture.
- blog: [https://medium.com/@kcimc/a-return-to-machine-learning-2de3728558eb#.bp2b1ax2x](https://medium.com/@kcimc/a-return-to-machine-learning-2de3728558eb#.bp2b1ax2x)

# Resources

**Music, Art and Machine Intelligence Workshop 2016**

- youtube: [https://www.youtube.com/playlist?list=PL8h7Hk91ScJ2NKFS_i8y4DYk4Zg1LHn0a](https://www.youtube.com/playlist?list=PL8h7Hk91ScJ2NKFS_i8y4DYk4Zg1LHn0a)
